{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Pick_up_and_Drop_off_RL_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javier-jaime/Reinforcement_Learning_Demos/blob/main/Pick_up_and_Drop_off_RL_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TNO0phsMypJ"
      },
      "source": [
        "# IBM Deep Learning and Reinforcement Learning\n",
        "\n",
        "## Package Pick up and Drop off Route Optimization with Reinforcement Learning\n",
        "\n",
        "Based on:  https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
      ],
      "id": "2TNO0phsMypJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "given-segment"
      },
      "source": [
        "import gym\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "import seaborn as sns\n",
        "from collections import deque\n",
        "from collections import defaultdict\n",
        "from time import sleep\n",
        "import sys\n",
        "import math"
      ],
      "id": "given-segment",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "encouraging-surname"
      },
      "source": [
        "## This Project use the Taxi-v3 Environment\n",
        "from OpenAI Gym (https://gym.openai.com/docs/)\n",
        "\n",
        "The job is to pick up a package at one location and drop him off in the right location in the minimum time possible."
      ],
      "id": "encouraging-surname"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlimited-friendly"
      },
      "source": [
        "env = gym.make(\"Taxi-v3\").env # Build a fresh environment"
      ],
      "id": "unlimited-friendly",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duplicate-registration",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7559368-0263-463b-fb04-413c62869ff7"
      },
      "source": [
        "env.render() # Renders one frame of the environment "
      ],
      "id": "duplicate-registration",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dried-inclusion",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ed5f6c-000d-40bf-eed8-4a03b5d98783"
      },
      "source": [
        "env.reset()  # Resets the environment and returns a random initial state\n",
        "env.render()\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "id": "dried-inclusion",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | :\u001b[43m \u001b[0m:G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhKFSqEaRopX"
      },
      "source": [
        "### Action/State Space"
      ],
      "id": "vhKFSqEaRopX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expensive-course"
      },
      "source": [
        "We have 6 possible actions:\n",
        "0 = south,\n",
        "1 = north,\n",
        "2 = east,\n",
        "3 = west,\n",
        "4 = pickup &\n",
        "5 = dropoff\n",
        "\n",
        "And 4 possible pickup and destination locations: R, G, Y & B.\n",
        "\n",
        "The blue letter represents the current pick-up location, and the purple letter is the current destination. The filled square represents the vehicle, which is yellow without a package and green with one. The pipe (\"|\") represents a wall which the vehicle cannot cross."
      ],
      "id": "expensive-course"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "external-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b11f4c7-e841-4e29-d3fb-53f37a0e88ad"
      },
      "source": [
        "state = env.encode(3, 2, 1, 0) # (row, column, passenger index, destination index)\n",
        "print(\"State:\", state)\n",
        "\n",
        "env.s = state\n",
        "env.render()"
      ],
      "id": "external-inventory",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State: 344\n",
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "removed-smooth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df34b9c3-f026-48c2-8daf-1b7e15f51f3b"
      },
      "source": [
        "env.P[344] # Dictionary with structure: {action: [(probability, nextstate, reward, done)]}"
      ],
      "id": "removed-smooth",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 444, -1, False)],\n",
              " 1: [(1.0, 244, -1, False)],\n",
              " 2: [(1.0, 344, -1, False)],\n",
              " 3: [(1.0, 324, -1, False)],\n",
              " 4: [(1.0, 344, -10, False)],\n",
              " 5: [(1.0, 344, -10, False)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih_fK2kUtvRt"
      },
      "source": [
        "### Try to Solve the environment with brute force (random) and not RL\n",
        "Rewards: You will receive +20 points for a successful dropoff, and lose 1 point for every timestep it takes.\n",
        "\n",
        "There is also a 10 point penalty for illegal pick-up and drop-off actions."
      ],
      "id": "ih_fK2kUtvRt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zGJaFitGI9",
        "outputId": "74b3f693-f26a-445a-b5f1-d14c2ba847c6"
      },
      "source": [
        "env.s = 344  # set environment to the state above\n",
        "\n",
        "epochs = 0\n",
        "penalties = 0\n",
        "reward = 0\n",
        "\n",
        "frames = [] # for animation\n",
        "\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample() # we can randomly sample actions\n",
        "    state, reward, done, info = env.step(action) # Step the environment by one timestep\n",
        "\n",
        "    if reward == -10:\n",
        "        penalties += 1\n",
        "    \n",
        "    # Put each rendered frame into dict for animation\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "    )\n",
        "    epochs += 1\n",
        "    \n",
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalties))"
      ],
      "id": "c-zGJaFitGI9",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timesteps taken: 1705\n",
            "Penalties incurred: 553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYbxp79Hu-9-",
        "outputId": "98efa3b6-57ff-49c9-f016-c1c4301d3d30"
      },
      "source": [
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.1)\n",
        "        \n",
        "print_frames(frames)"
      ],
      "id": "EYbxp79Hu-9-",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 1705\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCn1qZqFyFOs"
      },
      "source": [
        "Not good! It took a lot of steps for only one drop."
      ],
      "id": "ZCn1qZqFyFOs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7NoAiPgydS7"
      },
      "source": [
        "## Q-Learning\n",
        "\n",
        "Q-values are updated using the equation:\n",
        "\n",
        "Q(state,action)←(1−α)Q(state,action)+α(reward+γmaxaQ(next state,all actions))\n",
        "\n",
        "Where:\n",
        "- α (alpha) is the learning rate (0<α≤1)\n",
        "- γ (gamma) is the discount factor (0≤γ≤1)\n",
        "\n",
        "The Q-table is a matrix where we have a row for every state (500) and a column for every action (6). "
      ],
      "id": "g7NoAiPgydS7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technological-charge"
      },
      "source": [
        "q_table = np.zeros([env.observation_space.n, env.action_space.n]) # Initialize the Q-table by all zeros"
      ],
      "id": "technological-charge",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGiWPNn1lVM"
      },
      "source": [
        "### Training the agent (See below for Hyperparameters Optimization)"
      ],
      "id": "9kGiWPNn1lVM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chronic-things",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04edafe-c1b4-4216-d6a0-e88abc253fa9"
      },
      "source": [
        "%%time\n",
        "\n",
        "max_episodes = 500000\n",
        "\n",
        "# Set Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "\n",
        "# For storing and plotting the metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "random_seed= 42 # 42 is The Answer To Life, The Universe and Everything\n",
        "rng =np.random.default_rng(random_seed)\n",
        "\n",
        "for i in range(1, max_episodes+1):\n",
        "    state = env.reset()\n",
        "\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        if rng.random() < epsilon:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state]) # Exploit learned values\n",
        "\n",
        "        next_state, reward, done, info = env.step(action) \n",
        "        \n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "        \n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "        \n",
        "    if i % 1000 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "id": "chronic-things",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 500000\n",
            "Training finished.\n",
            "\n",
            "CPU times: user 4min 7s, sys: 34 s, total: 4min 41s\n",
            "Wall time: 4min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHL5d32T3tFq",
        "outputId": "c72066ec-da98-4c4e-d8ab-75280ecb9fa4"
      },
      "source": [
        "# From the Q-Table if we are in the state 344 from above, we should go north\n",
        "\n",
        "print(q_table[344], \"max value\", max(q_table[344]), \"is in place 1, this is north\")"
      ],
      "id": "GHL5d32T3tFq",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -2.49364522  -2.48236806  -2.48942067  -2.49365213 -11.48815677\n",
            " -11.48881832] max value -2.482368063078398 is in place 1, this is north\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_yuVxOK6nAQ"
      },
      "source": [
        "### Evaluating the Agent"
      ],
      "id": "1_yuVxOK6nAQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arctic-lawyer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a24b0c-e990-4041-8e77-557a92b54dd3"
      },
      "source": [
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 1000\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()  # reset environment to a new, random state\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "id": "arctic-lawyer",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 1000 episodes:\n",
            "Average timesteps per episode: 13.006\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introductory-fashion"
      },
      "source": [
        "The agent's performance improved considerably from the random example above"
      ],
      "id": "introductory-fashion"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOegG8Ap52o3"
      },
      "source": [
        "### Play a random episode in slow motion"
      ],
      "id": "LOegG8Ap52o3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rocky-initial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2884200c-3261-48b6-97a3-37e8942f7090"
      },
      "source": [
        "state = env.reset()  # reset environment to a new, random state\n",
        "env.render()\n",
        "time.sleep(0.5)\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    state, reward, done, info = env.step(action)\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    print(reward)\n",
        "    time.sleep(0.5)"
      ],
      "id": "rocky-initial",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCS3Xh7A-ryt"
      },
      "source": [
        "## Hyperparameter Tuning"
      ],
      "id": "PCS3Xh7A-ryt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8YewDcCA59l"
      },
      "source": [
        "# Define Agent Class\n",
        "\n",
        "class Agent:\n",
        "\n",
        "    def __init__(self, algorithm='sarsamax', start_epsilon=1, epsilon_decay=0.9, epsilon_cut=0.1, alpha=0.01, gamma=1,\n",
        "                 nA=6):\n",
        "        \"\"\" Initialize agent.\n",
        "        Params\n",
        "        ======\n",
        "        - nA: number of actions available to the agent\n",
        "        \"\"\"\n",
        "\n",
        "        algos = {\n",
        "            'sarsamax': self.step_sarsamax,\n",
        "            'exp_sarsa': self.step_exp_sarsa\n",
        "        }\n",
        "\n",
        "        self.step = algos[algorithm]\n",
        "        self.Q = defaultdict(lambda: np.zeros(self.nA))\n",
        "        self.epsilon, self.epsilon_decay, self.epsilon_cut, self.alpha, self.gamma, self.nA = \\\n",
        "            start_epsilon, epsilon_decay, epsilon_cut, alpha, gamma, nA\n",
        "\n",
        "    def select_action(self, state):\n",
        "        r = random.random()\n",
        "        if r > self.epsilon:   # select greedy action with probability epsilon\n",
        "            return np.argmax(self.Q[state])\n",
        "        else:  # otherwise, select an action randomly\n",
        "            return random.randint(0, 5)\n",
        "\n",
        "    def get_probs(self, Q_s, epsilon, nA):\n",
        "        \"\"\" obtains the action probabilities corresponding to epsilon-greedy policy \"\"\"\n",
        "        policy_s = np.ones(nA) * epsilon / nA\n",
        "        best_a = np.argmax(Q_s)\n",
        "        policy_s[best_a] = 1 - epsilon + (epsilon / nA)\n",
        "        return policy_s\n",
        "\n",
        "    def step_exp_sarsa(self, state, action, reward, next_state, done):\n",
        "        \"\"\" Update the agent's knowledge, using the most recently sampled tuple.\n",
        "        Params\n",
        "        ======\n",
        "        - state: the previous state of the environment\n",
        "        - action: the agent's previous choice of action\n",
        "        - reward: last reward received\n",
        "        - next_state: the current state of the environment\n",
        "        - done: whether the episode is complete (True or False)\n",
        "        \"\"\"\n",
        "        if not done:\n",
        "            probs = self.get_probs(self.Q[next_state], self.epsilon, self.nA)\n",
        "\n",
        "            self.Q[state][action] += self.alpha * (\n",
        "                        reward + self.gamma * np.dot(probs, self.Q[next_state]) - self.Q[state][action])\n",
        "        else:\n",
        "            self.Q[state][action] += self.alpha * (reward - self.Q[state][action])\n",
        "            self.epsilon = self.epsilon * self.epsilon_decay\n",
        "            if self.epsilon_cut is not None:\n",
        "                self.epsilon = max(self.epsilon, self.epsilon_cut)\n",
        "\n",
        "    def step_sarsamax(self, state, action, reward, next_state, done):\n",
        "        \"\"\" Update the agent's knowledge, using the most recently sampled tuple.\n",
        "        Params\n",
        "        ======\n",
        "        - state: the previous state of the environment\n",
        "        - action: the agent's previous choice of action\n",
        "        - reward: last reward received\n",
        "        - next_state: the current state of the environment\n",
        "        - done: whether the episode is complete (True or False)\n",
        "        \"\"\"\n",
        "        if not done:\n",
        "            self.Q[state][action] += self.alpha * (\n",
        "                        reward + self.gamma * np.max(self.Q[next_state]) - self.Q[state][action])\n",
        "        else:\n",
        "            self.Q[state][action] += self.alpha * (reward - self.Q[state][action])\n",
        "            self.epsilon = self.epsilon * self.epsilon_decay\n",
        "            if self.epsilon_cut is not None:\n",
        "                self.epsilon = max(self.epsilon, self.epsilon_cut)\n",
        "\n",
        "# Function interact to Monitor performance.\n",
        "\n",
        "def interact(env, agent, num_episodes=20000, window=100, print_logs=True):\n",
        "    \"\"\" Monitor agent's performance.\n",
        "    \n",
        "    Params\n",
        "    ======\n",
        "    - env: instance of OpenAI Gym's Taxi-v1 environment\n",
        "    - agent: instance of class Agent (see Agent.py for details)\n",
        "    - num_episodes: number of episodes of agent-environment interaction\n",
        "    - window: number of episodes to consider when calculating average rewards\n",
        "    Returns\n",
        "    =======\n",
        "    - avg_rewards: deque containing average rewards\n",
        "    - best_avg_reward: largest value in the avg_rewards deque\n",
        "    \"\"\"\n",
        "    # initialize average rewards\n",
        "    avg_rewards = deque(maxlen=num_episodes)\n",
        "    # initialize best average reward\n",
        "    best_avg_reward = -math.inf\n",
        "    # initialize monitor for most recent rewards\n",
        "    samp_rewards = deque(maxlen=window)\n",
        "    # for each episode\n",
        "    for i_episode in range(1, num_episodes+1):\n",
        "        # begin the episode\n",
        "        state = env.reset()\n",
        "        # initialize the sampled reward\n",
        "        samp_reward = 0\n",
        "        while True:\n",
        "            # agent selects an action\n",
        "            action = agent.select_action(state)\n",
        "            # agent performs the selected action\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            # agent performs internal updates based on sampled experience\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            # update the sampled reward\n",
        "            samp_reward += reward\n",
        "            # update the state (s <- s') to next time step\n",
        "            state = next_state\n",
        "            if done:\n",
        "                # save final sampled reward\n",
        "                samp_rewards.append(samp_reward)\n",
        "                break\n",
        "        if (i_episode >= 100):\n",
        "            # get average reward from last 100 episodes\n",
        "            avg_reward = np.mean(samp_rewards)\n",
        "            # append to deque\n",
        "            avg_rewards.append(avg_reward)\n",
        "            # update best average reward\n",
        "            if avg_reward > best_avg_reward:\n",
        "                best_avg_reward = avg_reward\n",
        "        # monitor progress\n",
        "        if print_logs:\n",
        "            print(\"\\rEpisode {}/{} || Best average reward {}\".format(i_episode, num_episodes, best_avg_reward), end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        # check if task is solved (according to OpenAI Gym)\n",
        "        if best_avg_reward >= 9.7:\n",
        "            if print_logs:\n",
        "                print('\\nEnvironment solved in {} episodes.'.format(i_episode), end=\"\")\n",
        "            break\n",
        "        if i_episode == num_episodes: print('\\n')\n",
        "    return avg_rewards, best_avg_reward"
      ],
      "id": "c8YewDcCA59l",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI4QpQYOWXvH"
      },
      "source": [
        "From a the python function we obtained the optimal sarsamax parameters"
      ],
      "id": "VI4QpQYOWXvH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4VLxUewJU7y"
      },
      "source": [
        "optimal_sarsa_max = {'algorithm': 'sarsamax','alpha': 0.2512238484351891, 'epsilon_cut': 0, 'epsilon_decay': 0.8888782926665223, 'start_epsilon': 0.9957089031634627, 'gamma': 0.7749915552696941}"
      ],
      "id": "r4VLxUewJU7y",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGp7QyUnKUcm",
        "outputId": "a0377a77-72a9-4484-dcc4-50a60bbca01c"
      },
      "source": [
        "env = gym.make('Taxi-v3')\n",
        "agent = Agent(**optimal_sarsa_max)\n",
        "avg_rewards_sarsamax, best_avg_reward_sarsamax = interact(env, agent)"
      ],
      "id": "fGp7QyUnKUcm",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 20000/20000 || Best average reward 8.72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIJUvBYxhPq7"
      },
      "source": [
        "data = pd.DataFrame(list(avg_rewards_sarsamax), columns=['reward'])\n",
        "data.loc[:,'episode'] = range(0,len(list(avg_rewards_sarsamax)))\n",
        "data.loc[:,'type'] = 'Sarsa Max'"
      ],
      "id": "RIJUvBYxhPq7",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "-Eg4qYGALf_m",
        "outputId": "5405ac49-0099-467a-ea37-0ec9d8327213"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns_plot = sns.lineplot(x='episode', y='reward',data = data[data.episode<1000])\n",
        "sns_plot.figure.savefig(\"tax1v3.png\")"
      ],
      "id": "-Eg4qYGALf_m",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}